<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>基于 tensorflow 的动漫人物识别 | buzi</title>
<meta name="description" content="记录平凡的修炼之路">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://littlebuzi.github.io//favicon.ico?v=1620226926695">
<link rel="stylesheet" href="https://littlebuzi.github.io//styles/main.css">


  
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css" />
  

  


<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>

<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />



  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://littlebuzi.github.io/">
        <img src="https://littlebuzi.github.io//images/avatar.png?v=1620226926695" class="site-logo">
        <h1 class="site-title">buzi</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            时间线
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            分类
          </a>
        
      
        
          <a href="https://littlebuzi.github.io/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      记录平凡的修炼之路
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">基于 tensorflow 的动漫人物识别</h2>
            <div class="post-date">2019-12-10</div>
            
              <div class="feature-container" style="background-image: url('https://user-images.githubusercontent.com/287255/43184241-ed3f1af8-9022-11e8-8800-468b002c73d9.png')">
              </div>
            
            <div class="post-content">
              <br>
<blockquote>
<ul>
<li>总目标：实现动漫人脸识别、建立动漫人脸数据库</li>
<li>本文定位在有一定python、linux基础和我这样的学生阅读</li>
<li>遇到问题❓/错误❌，请查看文末或文章间隙</li>
</ul>
</blockquote>
<h1 id="1-标注图片中动漫人物的脸部">1、标注图片中动漫人物的脸部</h1>
<p>环境：<br>
服务器：腾讯云（新用户优惠，阿里云之前使用了）<br>
操作系统：CetenOS 6.5 (环境配置复杂度: Window &gt; Centos &gt; Ubuntu 因个人原因使用centos较多)<br>
python版本：3.5（自带2.6.6）<br>
window端（客户端）工具：Xshell、Xftp</p>
<h2 id="11-依赖下载">1.1、依赖下载：</h2>
<p>① 动漫人脸分类器下载：</p>
<p>https://github.com/nagadomi/lbpcascade_animeface/</p>
<figure data-type="image" tabindex="1"><img src="https://littlebuzi.github.io//post-images/1573551561230.png" alt="" loading="lazy"></figure>
<p>② i2v库的安装：</p>
<p>Github：https://github.com/rezoo/illustration2vec/</p>
<figure data-type="image" tabindex="2"><img src="https://littlebuzi.github.io//post-images/1573048673712.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://littlebuzi.github.io//post-images/1573051147771.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="4"><img src="https://littlebuzi.github.io//post-images/1573051210275.png" alt="" loading="lazy"></figure>
<h2 id="12-test环境">1.2、Test环境：</h2>
<p>准备下linux服务器主机(centos)属性、环境：</p>
<ul>
<li>
<p><a href="https://jingyan.baidu.com/article/fdbd4277b16d1cb89e3f48e4.html">查看linux系统CPU和内存命令</a></p>
</li>
<li>
<p>python -V</p>
</li>
<li>
<p>安装anaconda（推荐安装中等较新版本，尽量避免未知错误）/ 安装pip（可能后续会出问题）<br>
<a href="https://blog.csdn.net/jh0218/article/details/85097061">CentOS 7安装Anaconda3</a></p>
</li>
<li>
<p>import cv2</p>
</li>
</ul>
<blockquote>
<p>可能会遇到anaconda崩了，涉及python多重版本conda软链接指向出了问题等：</p>
<ul>
<li><a href="https://blog.csdn.net/hubinbinheda/article/details/81175263">修改软链接</a></li>
<li><a href="https://codeday.me/bug/20190219/660678.html">修改.bashrc</a></li>
<li><a href="https://blog.csdn.net/qian2213762498/article/details/87385193">重新安装anaconda</a></li>
<li>或者使用了<a href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/">清华源</a>或其他源的旧版本，或<a href="https://www.anaconda.com/distribution/">官方版</a>的最新，尝试anaconda版本回退一点点</li>
</ul>
</blockquote>
<h2 id="13-参数查询-环境调试结束开始测试功能">1.3、参数查询、环境调试结束，开始测试功能：</h2>
<p>文件目录：<br>
<img src="https://littlebuzi.github.io//post-images/1573551285992.png" alt="" loading="lazy"></p>
<p>动漫人脸检测并截取：<br>
(尝试进行从一张图片中识别并截取人脸进行保存的操作)</p>
<pre><code class="language-python">
#coding=utf-8
import cv2
import sys
import os.path

cascade = cv2.CascadeClassifier('/root/comic/lbpcascade_animeface.xml')  # 引入xml
image = cv2.imread('/root/comic/test.jpg', cv2.IMREAD_COLOR)  # 读入一幅彩色图片
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 色彩空间转换
gray = cv2.equalizeHist(gray)  # 图像直方图均衡化

faces = cascade.detectMultiScale(gray,
                                 # detector options
                                 scaleFactor=1.1,
                                 minNeighbors=5,
                                 minSize=(24, 24))

i = 0
for (x, y, w, h) in faces:
    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)

    face = image[y: y + h, x:x + w, :]
    face = cv2.resize(face, (96, 96))
    save_filename = '%s_%d.png' % (os.path.basename('/root/comic/faces/').split('.')[0], i)
    cv2.imwrite(&quot;/root/comic/faces/&quot; + save_filename, face)
    i = i + 1

#cv2.imshow(&quot;AnimeFaceDetect&quot;, image)
cv2.waitKey(0)
cv2.imwrite(&quot;/root/comic/out.png&quot;, image)

</code></pre>
<hr>
<h1 id="2-截取并保存视频一帧帧截取到的动漫人脸目标">2、截取并保存视频一帧帧截取到的动漫人脸(目标)：</h1>
<h2 id="21-文件目录">2.1、文件目录：</h2>
<figure data-type="image" tabindex="5"><img src="https://littlebuzi.github.io//post-images/1573556199362.png" alt="" loading="lazy"></figure>
<h2 id="22-导入视频一帧帧截取动漫人脸">2.2、导入视频一帧帧截取动漫人脸：</h2>
<pre><code class="language-python">
#coding=utf-8
import cv2
import os

face_id = 1
count = 0
cap = cv2.VideoCapture('/root/comic/1.mp4')
face_detector = cv2.CascadeClassifier('/root/comic/lbpcascade_animeface.xml')

while True:

    # 从摄像头读取图片
    sucess, img = cap.read()
    # 转为灰度图片
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # 检测人脸
    faces = face_detector.detectMultiScale(gray, 1.3, 5)
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x+w, y+w), (255, 0, 0))
        count += 1
        font = cv2.FONT_HERSHEY_TRIPLEX
        cv2.putText(img, 'num:%d' % (count), (x + 30, y + 30), font, 1, (255, 0, 255), 4)
        # 保存图像
        cv2.imwrite(&quot;/root/comic/characters/User.&quot; + str(face_id) + '.' + str(count) + '.jpg', gray[y: y + h, x: x + w])
        #cv2.imshow('image', img)
    # 保持画面的持续。
    k = cv2.waitKey(1)

    if k == 27:   # 通过esc键退出摄像
        break

# 关闭摄像头
cap.release()
cv2.destroyAllWindows()

</code></pre>
<hr>
<h2 id="22-分类图片">2.2、分类图片：</h2>
<p>将不同人物分类到属于他命名的文件夹下：</p>
<pre><code class="language-python">
#开发中

</code></pre>
<hr>
<h1 id="3-训练图片">3、训练图片：</h1>
<p>开始制定、训练出模型(代码太长影响观感,完整代码<a href="https://github.com/littlebuzi/">github</a>)：</p>
<pre><code class="language-python">
#coding=utf-8
from skimage import io, transform
import glob
import os
import tensorflow as tf
import numpy as np
import time
import matplotlib.pyplot as plt

# 训练验证数据集目录
path = '/root/comic_reg/data/train-validation-set/'#最后少了个斜杠 读入失败
# 模型保存地址，最后接的是模型名字
model_path = '/root/comic_reg/model/model.ckpt'

# 将所有的图片resize成100*100

# 读取图片

# 打乱顺序

# 将所有数据分为训练集和验证集
ratio = 0.7
s = np.int(num_example*ratio)
x_train = data[:s]
y_train = label[:s]
x_val = data[s:]
y_val = label[s:]

# -----------------构建网络----------------------
# 占位符
x = tf.placeholder(tf.float32, shape=[None, w, h, c], name='x')
y_ = tf.placeholder(tf.int32, shape=[None, ], name='y_')

# 第一个卷积层（100——&gt;50)

# 第二个卷积层(50-&gt;25)

# 第三个卷积层(25-&gt;12)

# 第四个卷积层(12-&gt;6)

# 全连接层

# ---------------------------网络结束---------------------------

# (小处理)将logits乘以1赋值给logits_eval，定义name，方便在后续调用模型时通过tensor名字调用输出tensor

# 定义一个函数，按批次取数据

# 训练和测试数据，可将n_epoch设置更大一些
n_epoch = 50
batch_size = 32
saver = tf.train.Saver()
sess = tf.Session()
sess.run(tf.global_variables_initializer())

# 自定义保存数据列表
trainlosslist = []
trainacclist = []
validationlosslist = []
validationacclist = []


for epoch in range(n_epoch):
    start_time = time.time()
    
    # training
    train_loss, train_acc, n_batch = 0, 0, 0
    for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True):
        _, err, ac = sess.run([train_op,loss,acc], feed_dict={x: x_train_a, y_: y_train_a})
        train_loss += err; train_acc += ac; n_batch += 1
    print(&quot;   train loss: %f&quot; % (train_loss / n_batch))
    print(&quot;   train acc: %f&quot; % (train_acc / n_batch))
    # 添加到列表
    trainlosslist.append(train_loss / n_batch)
    trainacclist.append(train_acc / n_batch)

    # validation
    val_loss, val_acc, n_batch = 0, 0, 0
    for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False):
        err, ac = sess.run([loss, acc], feed_dict={x: x_val_a, y_: y_val_a})
        val_loss += err; val_acc += ac; n_batch += 1
    print(&quot;   validation loss: %f&quot; % (val_loss / n_batch))
    print(&quot;   validation acc: %f&quot; % (val_acc / n_batch))
    # 添加到列表
    validationlosslist.append(val_loss / n_batch)
    validationacclist.append(val_acc / n_batch)

saver.save(sess,model_path)
sess.close()

# 绘图
x = np.arange(1, n_epoch, 1)

plt.plot(x, np.array(trainacclist)[x-1], label=&quot;train-acc&quot;)
plt.plot(x, np.array(validationacclist)[x-1], label=&quot;validation-acc&quot;)
plt.plot(x, np.array(trainlosslist)[x-1], label=&quot;train-loss&quot;)
plt.plot(x, np.array(validationlosslist)[x-1], label=&quot;validation-loss&quot;)

# 设置坐标轴名称
plt.xlabel('epoch')

# 画两条基准线
plt.plot(x, x/x, label=&quot;one&quot;)
plt.plot(x, x-x, label=&quot;zero&quot;)

# 参数：loc设置显示的位置，0是自适应；ncol设置显示的列数
plt.legend(loc=0, ncol=1)   
#plt.show()
plt.savefig(&quot;/root/comic_reg/out.png&quot;)

</code></pre>
<hr>
<h1 id="4-识别图片">4、识别图片：</h1>
<pre><code class="language-python">
from skimage import io,transform
import tensorflow as tf
import numpy as np
import glob

path = '/root/comic_reg/data/test-set/*.png'

image_dict = {0: '一花',1:'二乃',2:'三玖',3:'四叶',4:'五月'}
count_true=[]

w=100
h=100
c=3

def read_one_image(path):
    img = io.imread(path)
    img = transform.resize(img,(w,h))
    return np.asarray(img)

with tf.Session() as sess:
    data = []
  
    # 目录列表
    paths = glob.glob(path)
    #print(paths)
    for img in paths:
        data.append(read_one_image(img))

    saver = tf.train.import_meta_graph('/root/comic_reg/model/model.ckpt.meta')
    saver.restore(sess,tf.train.latest_checkpoint('/root/comic_reg/model/'))

    graph = tf.get_default_graph()
    x = graph.get_tensor_by_name(&quot;x:0&quot;)
    feed_dict = {x:data}

    logits = graph.get_tensor_by_name(&quot;logits_eval:0&quot;)

    classification_result = sess.run(logits,feed_dict)
    

    #打印出预测矩阵
    print(&quot;\n预测矩阵:\n&quot;, classification_result)
    #打印出预测矩阵每一行最大值的索引
    print(&quot;\n简略结果:\n&quot;, tf.argmax(classification_result,1).eval(), '\n')
    print(&quot;具体情况: &quot;)
    #根据索引通过字典对应人物的分类
    output = []
    output = tf.argmax(classification_result,1).eval()
    count = 0
    for i in range(len(output)):
        # output[i]是测试结果编码，paths[i])[-7]是原定图片编号（路飞1）
        flag = False
        if str(output[i]+1) == paths[i][-7]:
            flag = True
            if flag == True:
                count_true.append(paths[i][-7:])
            count += 1
        print(&quot;第 &quot; + str(i+1) +  &quot; 张 (&quot; +   paths[i][-7:] + &quot;) 人物预测: &quot; + image_dict[output[i]]  + &quot; &quot; + str(flag))
    print(&quot;\n准确率: {:.2f}%&quot;.format(count / len(output) * 100 ))

print(count_true)

</code></pre>
<hr>
<p>结果：<br>
<img src="https://littlebuzi.github.io//post-images/1575866273011.png" alt="" loading="lazy"><br>
因为只有第一个人物图片准备充足所以其他人物识别率会偏低</p>
<hr>
<p>之前使用：</p>
<p>服务器：腾讯云<br>
操作系统：Ubuntu Server 18.04.1 LTS 64位<br>
类型：公共镜像（池）<br>
内存：2 GB<br>
CPU：1 核<br>
硬盘：50 G<br>
公网带宽：1 Mbps</p>
<hr>
<h2 id="步骤11中可能遇到的问题">步骤1.1中可能遇到的问题：</h2>
<p>1.下载速度太慢：</p>
<h2 id="法一">法一：</h2>
<p>liunx 下载 Github_Releases 下载提速：</p>
<p>Linux系统下hosts文件的位置是 /etc/hosts ，以root用户登录Linux，使用vi编辑/etc/hosts文件，将附加的内容添加在其后面即可：</p>
<p>修改hosts(liunx):<br>
52.216.186.155 github-production-release-asset-2e65be.s3.amazonaws.com</p>
<figure data-type="image" tabindex="6"><img src="https://littlebuzi.github.io//post-images/1573051669990.png" alt="" loading="lazy"></figure>
<pre><code class="language-linux">
wget https://github.com/rezoo/illustration2vec/releases/download/v2.0.0/illust2vec_tag_ver200.caffemodel

以此类推...

</code></pre>
<h2 id="法二">法二：</h2>
<p>修改hosts(window):</p>
<p>当我们需要本地调试网站或者屏蔽某个网站的时候可以手动将这个网站添加到系统hosts文件中，因为hosts文件的优先级高于DNS，所以可以达到你想要在浏览器里呈现的结果，当然这只在本地有用！<br>
一、Windows中hosts文件一般在C:\Windows\System32\drivers\etc目录下，格式是</p>
<pre><code>127.0.0.1 localhost
::1 localhost
52.216.186.155 github-production-release-asset-2e65be.s3.amazonaws.com
</code></pre>
<p>可以用记事本修改，前面是IP地址，后面是域名。127.0.0.1这个是本地环回地址。<br>
比如127.0.0.1 www.baidu.com就是把www.baidu.com这个域名指向127.0.0.1的地址。</p>
<p>##法三：<br>
Github镜像网站：http://github-mirror.bugkiller.org/</p>
<h2 id="xftp传上去云端">xftp传上去云端</h2>
<p>当然这也需要很久 不多折合下来很大可能快50-100倍。如果像我一样有一台window云服务，那就让它来做这件事。下载，上传，都在云上进行。</p>
<h2 id="详细请看">详细请看</h2>
<p><a href="https://www.cmsky.com/linux-hosts/">https://www.cmsky.com/linux-hosts/</a></p>
<hr>
<h2 id="步骤22中可能遇到的问题">步骤2.2中可能遇到的问题：</h2>
<pre><code>
【Linux】 解决报错： 
ImportError: libSM.so.6: cannot open shared object file: No such file or directory

原因：
libSM、libSM等不存在

解决办法：
yum install xxx

详：https://www.cnblogs.com/richerdyoung/p/8458910.html

</code></pre>
<hr>
<h2 id="步骤23中可能遇到的问题">步骤2.3中可能遇到的问题：</h2>
<p>查看linux系统CPU和内存命令</p>
<p>https://jingyan.baidu.com/article/fdbd4277b16d1cb89e3f48e4.html</p>
<p>Python MemoryError</p>
<p>https://blog.csdn.net/xiaopihaierletian/article/details/57416110</p>
<p>在用Python处理大数据时，本来16G的内存，内存还没使用四分之一就开始报MemoryError的错误，后来才知道32bit的Python使用内存超过2G之后，就报这个错误，还没有其他的提示消息。果断换64bit的Python。</p>
<p>https://blog.csdn.net/weixin_33928137/article/details/93646975</p>
<p>https://blog.csdn.net/xovee/article/details/101077022</p>
<p>linux 使用文件增加虚拟内存 swap</p>
<p>https://msd.misuland.com/pd/3070888491219949990</p>
<p>https://www.cnblogs.com/ling-yu-amen/p/10819879.html</p>
<h2 id="import-cv2-找不到-face">import cv2 找不到 face</h2>
<p>AttributeError: module 'cv2.face' has no attribute 'createEigenFaceRecognizer' 解决办法</p>
<p>原因：</p>
<p>一.版本问题，目前使用版本cv2.face中createEigenFaceRecognizer更名或移除<br>
解决：请查看对应版本的说明文档，使用对应版本或属性名。</p>
<p>二.未安装<br>
opencv_contrib，所以<br>
model = cv2.face.createEigenFaceRecognizer() 行找不到face<br>
解决：<br>
1.使用pip、源码安装方法</p>
<pre><code class="language-python">pip install opencv-python opencv-contrib-python
</code></pre>
<p>或<br>
<a href="https://blog.csdn.net/wyx100/article/details/78498609">https://blog.csdn.net/wyx100/article/details/78498609</a></p>
<p>2.conda ：</p>
<pre><code class="language-python">conda install opencv-python opencv-contrib-python
</code></pre>
<hr>
<br>
<p>问：博主你的代码有问题，你的项目文件夹怎么建的？<br>
答：项目还在开发中，这是俺滴毕设所以还未完善，只有个大概，望体谅<sub>谢谢大家</sub></p>
<p>工具：xftp、xshell：<a href="https://www.netsarang.com/zh/free-for-home-school/">https://www.netsarang.com/zh/free-for-home-school/</a></p>
<h1 id="参考文献">参考文献：</h1>
<p><a href="https://blog.csdn.net/abcd740181246/article/details/89878613">https://blog.csdn.net/abcd740181246/article/details/89878613</a></p>
<p><a href="https://blog.csdn.net/zyxhangiian123456789/article/details/87911999">https://blog.csdn.net/zyxhangiian123456789/article/details/87911999</a></p>
<p><a href="https://blog.csdn.net/qq_29007291/article/details/81103603">https://blog.csdn.net/qq_29007291/article/details/81103603</a></p>
<p><a href="https://blog.csdn.net/mozf881/article/details/84929443">https://blog.csdn.net/mozf881/article/details/84929443</a></p>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://littlebuzi.github.io/nKWkHExQP/" class="tag">
                    python
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://littlebuzi.github.io/face/">
                  <h3 class="post-title">
                    基于opencv的人脸识别签到系统 
                  </h3>
                </a>
              </div>
            

            
              
                <div id="gitalk-container" data-aos="fade-in"></div>
              

              
            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>

<script type="application/javascript">

AOS.init();

hljs.initHighlightingOnLoad()

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>


  
  
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>

      var gitalk = new Gitalk({
        clientID: 'e7c2b33da7e627d57c5a',
        clientSecret: '70bd30bae9adc0e0559d863df193af430483bcd1',
        repo: 'littlebuzi.github.io',
        owner: 'littlebuzi',
        admin: ['littlebuzi'],
        id: location.pathname,      // Ensure uniqueness and length less than 50
        distractionFreeMode: false  // Facebook-like distraction free mode
      })

      gitalk.render('gitalk-container')

    </script>
  

  




  </body>
</html>
