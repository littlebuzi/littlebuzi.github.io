
<html>
  <head lang="zh">
        <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"/>
        <meta content="yes" name="apple-mobile-web-app-capable"/>
        <meta content="black" name="apple-mobile-web-app-status-bar-style"/>
        <meta content="telephone=no" name="format-detection"/>
        <meta name="renderer" content="webkit">
    <title>基于 tensorflow 的动漫人物识别 | buzi</title>
<link href="https://littlebuzi.github.io//styles/main.css" type="text/css" rel="stylesheet"/>
<script type="text/javascript" src="https://littlebuzi.github.io//media/scripts/jquery.js"></script>
<script type="text/javascript" src="https://littlebuzi.github.io//media/scripts/basic.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  </head>

  <body>
     <div class="header">
      <div class="logo_title">
		  
        <div class="title animated fadeInDown"><img src="https://littlebuzi.github.io//images/avatar.png?v=1575867288757"/>

          <h1 title="buzi" class="weaklink"><a href="/">buzi</a>

          </h1>

          <div class="navbar weaklink">
            <div class="normal_nav">

<div class="bitcron_nav_container">


  <div class="bitcron_nav">
    <div class="mixed_site_nav_wrap site_nav_wrap">
		
      <ul class="mixed_site_nav site_nav sm sm-base">
 
  <li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/" class="selected active current nav__item" >首页</a>

  </li>
 
  <li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/archives" class="selected active current nav__item" >时间线</a>

  </li>
 
  <li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/tags" class="selected active current nav__item" >分类</a>

  </li>
 
  <li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/post/about" class="selected active current nav__item" >关于</a>

  </li>
 

      </ul>

      <div class="clear clear_nav_inline_end"></div>

    </div>

  </div>



  <div class="clear clear_nav_end"></div>

</div>

            </div>

            <div class="hamberger"><i class="fa fa-bars"></i>
<i class="fa fa-times"></i>

            </div>

          </div>

        </div>

      </div>

      <div class="hidden_nav animated fadeInDown">

<div class="bitcron_nav_container">


  <div class="bitcron_nav">
    <div class="mixed_site_nav_wrap site_nav_wrap">
      <ul class="mixed_site_nav site_nav sm sm-base">
		  
	
  <li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/" class="selected active current nav__item" >首页</a>

  </li>


  <li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/archives" class="selected active current nav__item" >时间线</a>

  </li>


  <li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/tags" class="selected active current nav__item" >分类</a>

  </li>


  <li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/post/about" class="selected active current nav__item" >关于</a>

  </li>





      </ul>

      <div class="clear clear_nav_inline_end"></div>

    </div>

  </div>



  <div class="clear clear_nav_end"></div>

</div>

      </div>

    </div>


    <div class="main">
      <div class="main-inner">


<div class="content">






  <div class="post_page" >

<div class="post">
  <div class="post_title sm_margin">
    <h2><a>基于 tensorflow 的动漫人物识别</a>



    </h2>
  </div>

  <div class="post_details">
    <div class="info"><i class="fa fa-clock-o"></i>
<span class="date_info">2019-10-25</span>
<i class="fa fa-eye"></i>

<span class="date_info"><span id="busuanzi_value_page_pv"></span> Views</span>


<i class="fa fa-bookmark-o"></i>
<span class="tags_info weaklink">
	
	<a href="https://littlebuzi.github.io//tag/nKWkHExQP" class="tag">python</a>


</span>


    </div>

  </div>





  <div class="post_content markdown"><p class="md_block">
    <span class="md_line md_line_start md_line_end"><h1 id="实现动漫人脸识别-建立动漫人脸数据库">实现动漫人脸识别、建立动漫人脸数据库：</h1>
<hr>
<br>
<p>【遇到问题❓/错误❌，请查看文末或文章间隙】</p>
<br>
<hr>
<br>
<h2 id="1-目标标注图片中动漫人物的脸部封面所示">1、目标：标注图片中动漫人物的脸部（封面所示）</h2>
<p>环境：<br>
服务器：腾讯云（新用户优惠，阿里云之前使用了）<br>
操作系统：CetenOS 6.5 (环境配置复杂度: Window &gt; Centos &gt; Ubuntu 因个人原因使用centos较多)<br>
python版本：3.5（自带2.6.6）<br>
window端（客户端）工具：Xshell、Xftp</p>
<hr>
<br>
<h2 id="11-依赖下载">1.1、依赖下载：</h2>
<p>① 动漫人脸分类器下载：</p>
<p>https://github.com/nagadomi/lbpcascade_animeface/</p>
<figure data-type="image" tabindex="1"><img src="https://littlebuzi.github.io//post-images/1573551561230.png" alt=""></figure>
<p>② i2v库的安装：</p>
<p>Github：https://github.com/rezoo/illustration2vec/</p>
<figure data-type="image" tabindex="2"><img src="https://littlebuzi.github.io//post-images/1573048673712.png" alt=""></figure>
<figure data-type="image" tabindex="3"><img src="https://littlebuzi.github.io//post-images/1573051147771.png" alt=""></figure>
<figure data-type="image" tabindex="4"><img src="https://littlebuzi.github.io//post-images/1573051210275.png" alt=""></figure>
<hr>
<br>
<h2 id="12-test环境">1.2、Test环境：</h2>
<p>准备下linux服务器主机(centos)属性、环境：</p>
<ul>
<li>
<p>1.<a href="https://jingyan.baidu.com/article/fdbd4277b16d1cb89e3f48e4.html">查看linux系统CPU和内存命令</a></p>
</li>
<li>
<p>2.python -V</p>
</li>
<li>
<p>3.安装anaconda（推荐安装中等较新版本，尽量避免未知错误）/ 安装pip（可能后续会出问题）<br>
<a href="https://blog.csdn.net/jh0218/article/details/85097061">CentOS 7安装Anaconda3</a></p>
</li>
<li>
<p>4.import cv2</p>
</li>
</ul>
<blockquote>
<p>可能会遇到anaconda崩了，涉及python多重版本conda软链接指向出了问题等：</p>
<ul>
<li><a href="https://blog.csdn.net/hubinbinheda/article/details/81175263">修改软链接</a></li>
<li><a href="https://codeday.me/bug/20190219/660678.html">修改.bashrc</a></li>
<li><a href="https://blog.csdn.net/qian2213762498/article/details/87385193">重新安装anaconda</a></li>
<li>或者使用了<a href="https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/">清华源</a>或其他源的旧版本，或<a href="https://www.anaconda.com/distribution/">官方版</a>的最新，尝试anaconda版本回退一点点</li>
</ul>
</blockquote>
<hr>
<br>
<h2 id="13-参数查询-环境调试结束开始测试功能">1.3、参数查询、环境调试结束，开始测试功能：</h2>
<p>文件目录：<br>
<img src="https://littlebuzi.github.io//post-images/1573551285992.png" alt=""></p>
<p>动漫人脸检测并截取：<br>
(尝试进行从一张图片中识别并截取人脸进行保存的操作)</p>
<pre><code class="language-python">
#coding=utf-8
import cv2
import sys
import os.path

cascade = cv2.CascadeClassifier('/root/comic/lbpcascade_animeface.xml')  # 引入xml
image = cv2.imread('/root/comic/test.jpg', cv2.IMREAD_COLOR)  # 读入一幅彩色图片
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 色彩空间转换
gray = cv2.equalizeHist(gray)  # 图像直方图均衡化

faces = cascade.detectMultiScale(gray,
                                 # detector options
                                 scaleFactor=1.1,
                                 minNeighbors=5,
                                 minSize=(24, 24))

i = 0
for (x, y, w, h) in faces:
    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)

    face = image[y: y + h, x:x + w, :]
    face = cv2.resize(face, (96, 96))
    save_filename = '%s_%d.png' % (os.path.basename('/root/comic/faces/').split('.')[0], i)
    cv2.imwrite(&quot;/root/comic/faces/&quot; + save_filename, face)
    i = i + 1

#cv2.imshow(&quot;AnimeFaceDetect&quot;, image)
cv2.waitKey(0)
cv2.imwrite(&quot;/root/comic/out.png&quot;, image)

</code></pre>
<h2 id="br"><br></h2>
<h2 id="2-目标截取并保存视频一帧帧截取到的动漫人脸">2、目标：截取并保存视频一帧帧截取到的动漫人脸：</h2>
<br>
<h2 id="21-文件目录">2.1、文件目录：</h2>
<figure data-type="image" tabindex="5"><img src="https://littlebuzi.github.io//post-images/1573556199362.png" alt=""></figure>
<h2 id="22-导入视频一帧帧截取动漫人脸">2.2、导入视频一帧帧截取动漫人脸：</h2>
<pre><code class="language-python">
#coding=utf-8
import cv2
import os

face_id = 1
count = 0
cap = cv2.VideoCapture('/root/comic/1.mp4')
face_detector = cv2.CascadeClassifier('/root/comic/lbpcascade_animeface.xml')

while True:

    # 从摄像头读取图片
    sucess, img = cap.read()
    # 转为灰度图片
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # 检测人脸
    faces = face_detector.detectMultiScale(gray, 1.3, 5)
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x+w, y+w), (255, 0, 0))
        count += 1
        font = cv2.FONT_HERSHEY_TRIPLEX
        cv2.putText(img, 'num:%d' % (count), (x + 30, y + 30), font, 1, (255, 0, 255), 4)
        # 保存图像
        cv2.imwrite(&quot;/root/comic/characters/User.&quot; + str(face_id) + '.' + str(count) + '.jpg', gray[y: y + h, x: x + w])
        #cv2.imshow('image', img)
    # 保持画面的持续。
    k = cv2.waitKey(1)

    if k == 27:   # 通过esc键退出摄像
        break

# 关闭摄像头
cap.release()
cv2.destroyAllWindows()

</code></pre>
<hr>
<br>
<h2 id="22-分类图片">2.2、分类图片：</h2>
<p>将不同人物分类到属于他命名的文件夹下：</p>
<pre><code class="language-python">


</code></pre>
<hr>
<br>
<h2 id="3-训练图片">3、训练图片：</h2>
<p>开始制定、训练出模型：</p>
<pre><code class="language-python">
#coding=utf-8
from skimage import io, transform
import glob
import os
import tensorflow as tf
import numpy as np
import time
import matplotlib.pyplot as plt

# 训练验证数据集目录
path = '/root/comic_reg/data/train-validation-set/'#最后少了个斜杠 读入失败
# 模型保存地址，最后接的是模型名字
model_path = '/root/comic_reg/model/model.ckpt'

# 将所有的图片resize成100*100
w = 100
h = 100
c = 3


# 读取图片
def read_img(path):
    cate = [path+x for x in os.listdir(path) if os.path.isdir(path+x)]
    imgs = []
    labels = []
    for idx, folder in enumerate(cate):
        for im in glob.glob(folder+'/*.jpg')+glob.glob(folder+'/*.png'):#png和jpg需注意！！
            print('reading the images:%s'%(im))
            img = io.imread(im)
            img = transform.resize(img,(w,h))
            imgs.append(img)
            labels.append(idx)
    return np.asarray(imgs, np.float32), np.asarray(labels, np.int32)


data, label = read_img(path)
#print(data, label)


# 打乱顺序
num_example = data.shape[0]
arr = np.arange(num_example)
np.random.shuffle(arr)
data = data[arr]
label = label[arr]


# 将所有数据分为训练集和验证集
ratio = 0.7
s = np.int(num_example*ratio)
x_train = data[:s]
y_train = label[:s]
x_val = data[s:]
y_val = label[s:]

# -----------------构建网络----------------------
# 占位符
x = tf.placeholder(tf.float32, shape=[None, w, h, c], name='x')
y_ = tf.placeholder(tf.int32, shape=[None, ], name='y_')

# 第一个卷积层（100——&gt;50)
conv1 = tf.layers.conv2d(
    inputs=x,
    filters=32,
    kernel_size=[5, 5],
    padding=&quot;same&quot;,
    activation=tf.nn.relu,
    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

# 第二个卷积层(50-&gt;25)
conv2 = tf.layers.conv2d(
    inputs=pool1,
    filters=64,
    kernel_size=[5, 5],
    padding=&quot;same&quot;,
    activation=tf.nn.relu,
    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

# 第三个卷积层(25-&gt;12)
conv3 = tf.layers.conv2d(
    inputs=pool2,
    filters=128,
    kernel_size=[3, 3],
    padding=&quot;same&quot;,
    activation=tf.nn.relu,
    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)

# 第四个卷积层(12-&gt;6)
conv4 = tf.layers.conv2d(
    inputs=pool3,
    filters=128,
    kernel_size=[3, 3],
    padding=&quot;same&quot;,
    activation=tf.nn.relu,
    kernel_initializer=tf.truncated_normal_initializer(stddev=0.01))
pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)

re1 = tf.reshape(pool4, [-1, 6 * 6 * 128])

# 全连接层
dense1 = tf.layers.dense(inputs=re1, 
                         units=1024,
                         activation=tf.nn.relu,
                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),
                         kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))
dense2 = tf.layers.dense(inputs=dense1,
                         units=512,
                         activation=tf.nn.relu,
                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),
                         kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))
logits = tf.layers.dense(inputs=dense2,
                         units=5,
                         activation=None,
                         kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),
                         kernel_regularizer=tf.contrib.layers.l2_regularizer(0.003))

# ---------------------------网络结束---------------------------

# (小处理)将logits乘以1赋值给logits_eval，定义name，方便在后续调用模型时通过tensor名字调用输出tensor
b = tf.constant(value=1,dtype=tf.float32)
logits_eval = tf.multiply(logits, b, name='logits_eval')

loss = tf.losses.sparse_softmax_cross_entropy(labels=y_, logits=logits)
train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)
correct_prediction = tf.equal(tf.cast(tf.argmax(logits, 1), tf.int32), y_)
acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))


# 定义一个函数，按批次取数据
def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False):
    assert len(inputs) == len(targets)
    if shuffle:
        indices = np.arange(len(inputs))
        np.random.shuffle(indices)
    for start_idx in range(0, len(inputs) - batch_size + 1, batch_size):
        if shuffle:
            excerpt = indices[start_idx:start_idx + batch_size]
        else:
            excerpt = slice(start_idx, start_idx + batch_size)
        yield inputs[excerpt], targets[excerpt]


# 训练和测试数据，可将n_epoch设置更大一些
n_epoch = 50
batch_size = 32
saver = tf.train.Saver()
sess = tf.Session()
sess.run(tf.global_variables_initializer())

# 自定义保存数据列表
trainlosslist = []
trainacclist = []
validationlosslist = []
validationacclist = []

for epoch in range(n_epoch):
    start_time = time.time()
    
    # training
    train_loss, train_acc, n_batch = 0, 0, 0
    for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True):
        _, err, ac = sess.run([train_op,loss,acc], feed_dict={x: x_train_a, y_: y_train_a})
        train_loss += err; train_acc += ac; n_batch += 1
    print(&quot;   train loss: %f&quot; % (train_loss / n_batch))
    print(&quot;   train acc: %f&quot; % (train_acc / n_batch))
    # 添加到列表
    trainlosslist.append(train_loss / n_batch)
    trainacclist.append(train_acc / n_batch)

    # validation
    val_loss, val_acc, n_batch = 0, 0, 0
    for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False):
        err, ac = sess.run([loss, acc], feed_dict={x: x_val_a, y_: y_val_a})
        val_loss += err; val_acc += ac; n_batch += 1
    print(&quot;   validation loss: %f&quot; % (val_loss / n_batch))
    print(&quot;   validation acc: %f&quot; % (val_acc / n_batch))
    # 添加到列表
    validationlosslist.append(val_loss / n_batch)
    validationacclist.append(val_acc / n_batch)

saver.save(sess,model_path)
sess.close()

# 绘图
x = np.arange(1, n_epoch, 1)

plt.plot(x, np.array(trainacclist)[x-1], label=&quot;train-acc&quot;)
plt.plot(x, np.array(validationacclist)[x-1], label=&quot;validation-acc&quot;)
plt.plot(x, np.array(trainlosslist)[x-1], label=&quot;train-loss&quot;)
plt.plot(x, np.array(validationlosslist)[x-1], label=&quot;validation-loss&quot;)

# 设置坐标轴名称
plt.xlabel('epoch')

# 画两条基准线
plt.plot(x, x/x, label=&quot;one&quot;)
plt.plot(x, x-x, label=&quot;zero&quot;)

# 参数：loc设置显示的位置，0是自适应；ncol设置显示的列数
plt.legend(loc=0, ncol=1)   
#plt.show()
plt.savefig(&quot;/root/comic_reg/out.png&quot;)

</code></pre>
<hr>
<br>
<h2 id="4-识别图片">4、识别图片：</h2>
<pre><code class="language-python">from skimage import io,transform
import tensorflow as tf
import numpy as np
import glob

path = '/root/comic_reg/data/test-set/*.png'

image_dict = {0: '一花',1:'二乃',2:'三玖',3:'四叶',4:'五月'}
count_true=[]

w=100
h=100
c=3

def read_one_image(path):
    img = io.imread(path)
    img = transform.resize(img,(w,h))
    return np.asarray(img)

with tf.Session() as sess:
    data = []
  
    # 目录列表
    paths = glob.glob(path)
    #print(paths)
    for img in paths:
        data.append(read_one_image(img))

    saver = tf.train.import_meta_graph('/root/comic_reg/model/model.ckpt.meta')
    saver.restore(sess,tf.train.latest_checkpoint('/root/comic_reg/model/'))

    graph = tf.get_default_graph()
    x = graph.get_tensor_by_name(&quot;x:0&quot;)
    feed_dict = {x:data}

    logits = graph.get_tensor_by_name(&quot;logits_eval:0&quot;)

    classification_result = sess.run(logits,feed_dict)
    

    #打印出预测矩阵
    print(&quot;\n预测矩阵:\n&quot;, classification_result)
    #打印出预测矩阵每一行最大值的索引
    print(&quot;\n简略结果:\n&quot;, tf.argmax(classification_result,1).eval(), '\n')
    print(&quot;具体情况: &quot;)
    #根据索引通过字典对应人物的分类
    output = []
    output = tf.argmax(classification_result,1).eval()
    count = 0
    for i in range(len(output)):
        # output[i]是测试结果编码，paths[i])[-7]是原定图片编号（路飞1）
        flag = False
        if str(output[i]+1) == paths[i][-7]:
            flag = True
            if flag == True:
                count_true.append(paths[i][-7:])
            count += 1
        print(&quot;第 &quot; + str(i+1) +  &quot; 张 (&quot; +   paths[i][-7:] + &quot;) 人物预测: &quot; + image_dict[output[i]]  + &quot; &quot; + str(flag))
    print(&quot;\n准确率: {:.2f}%&quot;.format(count / len(output) * 100 ))

print(count_true)

</code></pre>
<hr>
<br>
<p>结果：<br>
<img src="https://littlebuzi.github.io//post-images/1575866273011.png" alt=""><br>
因为只有第一个人物图片准备充足所以其他人物识别率会偏低</p>
<hr>
<br>
<p>之前使用：</p>
<p>服务器：腾讯云<br>
操作系统：Ubuntu Server 18.04.1 LTS 64位<br>
类型：公共镜像（池）<br>
内存：2 GB<br>
CPU：1 核<br>
硬盘：50 G<br>
公网带宽：1 Mbps</p>
<hr>
<br>
<h2 id="步骤11中可能遇到的问题">步骤1.1中可能遇到的问题：</h2>
<h1 id="1下载速度太慢">1.下载速度太慢：</h1>
<br>
<h2 id="法一">法一：</h2>
<p>liunx 下载 Github_Releases 下载提速：</p>
<p>Linux系统下hosts文件的位置是 /etc/hosts ，以root用户登录Linux，使用vi编辑/etc/hosts文件，将附加的内容添加在其后面即可：</p>
<p>修改hosts(liunx):<br>
52.216.186.155 github-production-release-asset-2e65be.s3.amazonaws.com</p>
<figure data-type="image" tabindex="6"><img src="https://littlebuzi.github.io//post-images/1573051669990.png" alt=""></figure>
<pre><code class="language-linux">
wget https://github.com/rezoo/illustration2vec/releases/download/v2.0.0/illust2vec_tag_ver200.caffemodel

以此类推...

</code></pre>
<h2 id="法二">法二：</h2>
<h3 id="修改hostswindow">修改hosts(window):</h3>
<p>当我们需要本地调试网站或者屏蔽某个网站的时候可以手动将这个网站添加到系统hosts文件中，因为hosts文件的优先级高于DNS，所以可以达到你想要在浏览器里呈现的结果，当然这只在本地有用！<br>
一、Windows中hosts文件一般在C:\Windows\System32\drivers\etc目录下，格式是</p>
<pre><code>127.0.0.1 localhost
::1 localhost
52.216.186.155 github-production-release-asset-2e65be.s3.amazonaws.com
</code></pre>
<p>可以用记事本修改，前面是IP地址，后面是域名。127.0.0.1这个是本地环回地址。<br>
比如127.0.0.1 www.baidu.com就是把www.baidu.com这个域名指向127.0.0.1的地址。</p>
<h3 id="xftp传上去云端">xftp传上去云端</h3>
<p>当然这也需要很久 不多折合下来很大可能快50-100倍。如果像我一样有一台window云服务，那就让它来做这件事。下载，上传，都在云上进行。</p>
<h3 id="详细请看">详细请看</h3>
<p><a href="https://www.cmsky.com/linux-hosts/">https://www.cmsky.com/linux-hosts/</a></p>
<hr>
<br>
<h2 id="步骤22中可能遇到的问题">步骤2.2中可能遇到的问题：</h2>
<pre><code>
【Linux】 解决报错： 
ImportError: libSM.so.6: cannot open shared object file: No such file or directory

原因：
libSM、libSM等不存在

解决办法：
yum install xxx

详：https://www.cnblogs.com/richerdyoung/p/8458910.html

</code></pre>
<hr>
<br>
<h2 id="步骤23中可能遇到的问题">步骤2.3中可能遇到的问题：</h2>
<p>查看linux系统CPU和内存命令</p>
<p>https://jingyan.baidu.com/article/fdbd4277b16d1cb89e3f48e4.html</p>
<p>Python MemoryError</p>
<p>https://blog.csdn.net/xiaopihaierletian/article/details/57416110</p>
<p>在用Python处理大数据时，本来16G的内存，内存还没使用四分之一就开始报MemoryError的错误，后来才知道32bit的Python使用内存超过2G之后，就报这个错误，还没有其他的提示消息。果断换64bit的Python。</p>
<p>https://blog.csdn.net/weixin_33928137/article/details/93646975</p>
<p>https://blog.csdn.net/xovee/article/details/101077022</p>
<p>linux 使用文件增加虚拟内存 swap</p>
<p>https://msd.misuland.com/pd/3070888491219949990</p>
<p>https://www.cnblogs.com/ling-yu-amen/p/10819879.html</p>
<hr>
<br>
<p>问：博主你的代码有问题，你的项目文件夹怎么建的？<br>
答：项目还在开发中，这是俺滴毕设所以还未完善，只有个大概，望体谅<sub>谢谢大家</sub></p>
</p>

     <p class="md_block">
    <div class="reward"><div class="reward-button">赏 <span class="reward-code"> <span class="alipay-code"> <img class="alipay-img" src="https://littlebuzi.github.io//media/images/alipay.png"><b>支付宝扫码打赏</b> </span> <span class="wechat-code"> <img class="wechat-img" src="https://littlebuzi.github.io//media/images/wechat.png"><b>微信打赏</b> </span> </span></div></div>
</p> 
</div>

</div>



<link href="https://littlebuzi.github.io//styles/main.css" type="text/css" rel="stylesheet"/>

<div class="doc_comments">

          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'e7c2b33da7e627d57c5a',
    clientSecret: '70bd30bae9adc0e0559d863df193af430483bcd1',
    repo: 'littlebuzi.github.io',
    owner: 'littlebuzi',
    admin: ['littlebuzi'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          
			  
          
        
</div>



  </div>
</div>



      </div>




    </div>

   <div class="footer">
<link href="https://littlebuzi.github.io//styles/main.css" type="text/css" rel="stylesheet"/><div class="site_footer_wrap"><div class="site_footer">

      <div class="mysocials"><div class="my_socials">
		   
			   
    
			   
    
			   
    
			   
    
</div><link href="https://littlebuzi.github.io//styles/main.css" type="text/css" rel="stylesheet"/>

      </div>

      <div class="copyright">Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
      </div>

</div></div>

    </div>


<style type="text/css">a.back_to_top {
    text-decoration: none;
    position: fixed;
    bottom: 40px;
    right: 30px;
    background: #f0f0f0;
    height: 40px;
    width: 40px;
    border-radius: 50%;
    line-height: 36px;
    font-size: 18px;
    text-align: center;
    transition-duration: .5s;
    transition-propety: background-color;
    display: none;
}

a.back_to_top span {
    color: #888;
}

a.back_to_top:hover {
    cursor: pointer;
    background: #dfdfdf;
}

a.back_to_top:hover span {
    color: #555;
}

@media print, screen and (max-width: 580px) {
    .back_to_top {
        display: none !important;
    }
}



</style><a id="back_to_top" href="#" class="back_to_top"><span>△</span>
</a>
<script type="text/javascript" src="https://littlebuzi.github.io//media/scripts/jquery.js"></script>

<script>$(document).ready((function(_this) {
  return function() {
    var bt;
    bt = $('#back_to_top');
    if ($(document).width() > 480) {
      $(window).scroll(function() {
        var st;
        st = $(window).scrollTop();
        if (st > 30) {
          return bt.css('display', 'block');
        } else {
          return bt.css('display', 'none');
        }
      });
      return bt.click(function() {
        $('body,html').animate({
          scrollTop: 0
        }, 800);
        return false;
      });
    }
  };
})(this));
</script>

</body>

</html>